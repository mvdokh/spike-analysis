{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "096a4540",
   "metadata": {},
   "source": [
    "# PSTH Analysis - Interactive Notebook\n",
    "\n",
    "This notebook provides an interactive interface for analyzing Peri-Stimulus Time Histograms (PSTH) from neural spike data around stimulus intervals.\n",
    "\n",
    "## Features:\n",
    "- Configurable time windows (before/after stimulus)\n",
    "- Unit selection and analysis\n",
    "- Channel-based analysis\n",
    "- Comprehensive visualizations\n",
    "- Statistical summaries\n",
    "\n",
    "## Data Structure:\n",
    "- **spikes_time_adjusted.csv**: Spike data with columns [time, unit, channel]\n",
    "- **pico.csv**: Stimulus intervals with columns [Start, End]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6057582f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from psth_analysis import PSTHAnalyzer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set up plotting parameters\n",
    "plt.style.use('default')\n",
    "sns.set_palette(\"husl\")\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5742334",
   "metadata": {},
   "source": [
    "## Configuration & Data Loading\n",
    "\n",
    "Set your analysis parameters here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "419f9434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ANALYSIS PARAMETERS - Modify these as needed\n",
    "PRE_TIME = 1000    # Time before stimulus onset (ms)\n",
    "POST_TIME = 2000   # Time after stimulus onset (ms)\n",
    "BIN_SIZE = 50      # Bin size for histogram (ms)\n",
    "SMOOTHING = 3      # Smoothing window (bins) - set to None for no smoothing\n",
    "\n",
    "# Visualization parameters\n",
    "PLOT_RASTER = True  # Show raster plots\n",
    "MAX_UNITS_GRID = 20 # Maximum units to show in grid plot\n",
    "FIGURE_DPI = 150    # Figure resolution\n",
    "\n",
    "print(f\"Analysis window: -{PRE_TIME}ms to +{POST_TIME}ms\")\n",
    "print(f\"Bin size: {BIN_SIZE}ms\")\n",
    "print(f\"Smoothing: {SMOOTHING} bins\" if SMOOTHING else \"No smoothing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fdeb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the PSTH analyzer\n",
    "analyzer = PSTHAnalyzer(\n",
    "    spikes_file='spikes_time_adjusted.csv',\n",
    "    intervals_file='pico.csv'\n",
    ")\n",
    "\n",
    "print(f\"\\nData loaded successfully!\")\n",
    "print(f\"Total units: {analyzer.n_units}\")\n",
    "print(f\"Total channels: {analyzer.n_channels}\")\n",
    "print(f\"Unit range: {min(analyzer.units)} - {max(analyzer.units)}\")\n",
    "print(f\"Channel range: {min(analyzer.channels)} - {max(analyzer.channels)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c4b2c54",
   "metadata": {},
   "source": [
    "## Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253d490e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display data summaries\n",
    "print(\"SPIKE DATA SUMMARY:\")\n",
    "print(analyzer.spikes_df.describe())\n",
    "\n",
    "print(\"\\nINTERVAL DATA SUMMARY:\")\n",
    "print(analyzer.intervals_df.describe())\n",
    "\n",
    "# Show first few rows\n",
    "print(\"\\nFirst 5 spikes:\")\n",
    "print(analyzer.spikes_df.head())\n",
    "\n",
    "print(\"\\nFirst 5 intervals:\")\n",
    "print(analyzer.intervals_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe96f312",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot distribution of units and channels\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "\n",
    "# Unit distribution\n",
    "unit_counts = analyzer.spikes_df['unit'].value_counts().sort_index()\n",
    "axes[0,0].bar(unit_counts.index, unit_counts.values, alpha=0.7)\n",
    "axes[0,0].set_xlabel('Unit ID')\n",
    "axes[0,0].set_ylabel('Spike Count')\n",
    "axes[0,0].set_title('Spikes per Unit')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Channel distribution\n",
    "channel_counts = analyzer.spikes_df['channel'].value_counts().sort_index()\n",
    "axes[0,1].bar(channel_counts.index, channel_counts.values, alpha=0.7, color='orange')\n",
    "axes[0,1].set_xlabel('Channel ID')\n",
    "axes[0,1].set_ylabel('Spike Count')\n",
    "axes[0,1].set_title('Spikes per Channel')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Unit-Channel relationship\n",
    "unit_channel_df = analyzer.spikes_df.groupby(['unit', 'channel']).size().reset_index(name='spike_count')\n",
    "pivot_table = unit_channel_df.pivot(index='unit', columns='channel', values='spike_count').fillna(0)\n",
    "\n",
    "im = axes[1,0].imshow(pivot_table.values, aspect='auto', cmap='viridis', interpolation='nearest')\n",
    "axes[1,0].set_xlabel('Channel')\n",
    "axes[1,0].set_ylabel('Unit')\n",
    "axes[1,0].set_title('Unit-Channel Spike Distribution')\n",
    "plt.colorbar(im, ax=axes[1,0], label='Spike Count')\n",
    "\n",
    "# Interval duration distribution\n",
    "interval_durations = analyzer.intervals_df['End'] - analyzer.intervals_df['Start']\n",
    "axes[1,1].hist(interval_durations, bins=50, alpha=0.7, color='green')\n",
    "axes[1,1].set_xlabel('Interval Duration')\n",
    "axes[1,1].set_ylabel('Frequency')\n",
    "axes[1,1].set_title('Stimulus Interval Durations')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average interval duration: {interval_durations.mean():.1f} Â± {interval_durations.std():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a206fa7d",
   "metadata": {},
   "source": [
    "## PSTH Computation\n",
    "\n",
    "Now let's compute the PSTH for all or selected units:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96338bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 1: Analyze all units\n",
    "selected_units = None  # Will analyze all units\n",
    "\n",
    "# Option 2: Analyze specific units (uncomment and modify as needed)\n",
    "# selected_units = [3, 7, 8, 10, 11]  # Example unit selection\n",
    "\n",
    "# Option 3: Analyze top N units by spike count\n",
    "# top_n = 10\n",
    "# unit_counts = analyzer.spikes_df['unit'].value_counts()\n",
    "# selected_units = unit_counts.head(top_n).index.tolist()\n",
    "# print(f\"Selected top {top_n} units: {selected_units}\")\n",
    "\n",
    "# Compute PSTH\n",
    "print(\"Computing PSTH...\")\n",
    "psth_data = analyzer.compute_psth(\n",
    "    pre_time=PRE_TIME,\n",
    "    post_time=POST_TIME,\n",
    "    bin_size=BIN_SIZE,\n",
    "    units=selected_units,\n",
    "    smoothing_window=SMOOTHING\n",
    ")\n",
    "\n",
    "print(f\"PSTH computed for {len(psth_data)} units\")\n",
    "print(f\"Time bins: {len(list(psth_data.values())[0]['bin_centers'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee287fe",
   "metadata": {},
   "source": [
    "## Individual Unit Analysis\n",
    "\n",
    "Let's examine individual units in detail:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cbdf615",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a unit to examine in detail\n",
    "# You can change this to any unit ID in your data\n",
    "EXAMPLE_UNIT = list(psth_data.keys())[0]  # First available unit\n",
    "\n",
    "print(f\"Analyzing Unit {EXAMPLE_UNIT} in detail\")\n",
    "print(f\"Available units: {sorted(list(psth_data.keys()))}\")\n",
    "\n",
    "# Display unit statistics\n",
    "unit_data = psth_data[EXAMPLE_UNIT]\n",
    "print(f\"\\nUnit {EXAMPLE_UNIT} Statistics:\")\n",
    "print(f\"- Total spikes in analysis window: {unit_data['total_spikes']}\")\n",
    "print(f\"- Valid intervals: {unit_data['valid_intervals']}\")\n",
    "print(f\"- Peak firing rate: {np.max(unit_data['firing_rate']):.2f} Hz\")\n",
    "print(f\"- Average firing rate: {np.mean(unit_data['firing_rate']):.2f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "858dd6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot detailed PSTH for the selected unit\n",
    "plt.figure(figsize=(12, 8))\n",
    "analyzer.plot_psth_single_unit(EXAMPLE_UNIT, show_raster=PLOT_RASTER)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13008195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactive unit selection - change UNIT_TO_PLOT to explore different units\n",
    "UNIT_TO_PLOT = 10  # Change this value to any unit you want to examine\n",
    "\n",
    "if UNIT_TO_PLOT in psth_data:\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    analyzer.plot_psth_single_unit(UNIT_TO_PLOT, show_raster=PLOT_RASTER)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Show statistics for this unit\n",
    "    unit_data = psth_data[UNIT_TO_PLOT]\n",
    "    print(f\"\\nUnit {UNIT_TO_PLOT} Statistics:\")\n",
    "    print(f\"- Total spikes: {unit_data['total_spikes']}\")\n",
    "    print(f\"- Valid intervals: {unit_data['valid_intervals']}\")\n",
    "    print(f\"- Peak firing rate: {np.max(unit_data['firing_rate']):.2f} Hz\")\n",
    "    print(f\"- Baseline firing rate (first 25%): {np.mean(unit_data['firing_rate'][:len(unit_data['firing_rate'])//4]):.2f} Hz\")\n",
    "else:\n",
    "    print(f\"Unit {UNIT_TO_PLOT} not found in data. Available units: {sorted(list(psth_data.keys()))}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870b326f",
   "metadata": {},
   "source": [
    "## Population Analysis\n",
    "\n",
    "Now let's look at population-level patterns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78192154",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot PSTH grid for multiple units\n",
    "units_to_plot = list(psth_data.keys())[:MAX_UNITS_GRID]\n",
    "print(f\"Plotting PSTH grid for {len(units_to_plot)} units\")\n",
    "\n",
    "grid_fig = analyzer.plot_psth_grid(\n",
    "    units=units_to_plot,\n",
    "    ncols=4,\n",
    "    figsize=(16, 12),\n",
    "    show_statistics=True\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5702032",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Population PSTH (average across units)\n",
    "print(\"Creating population PSTH...\")\n",
    "pop_fig = analyzer.plot_population_psth(method='mean')\n",
    "plt.show()\n",
    "\n",
    "# Population PSTH (sum across units)\n",
    "pop_sum_fig = analyzer.plot_population_psth(method='sum')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdbb05d9",
   "metadata": {},
   "source": [
    "## Channel Analysis\n",
    "\n",
    "Let's analyze the data from a channel perspective:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eaee066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute channel-based analysis\n",
    "print(\"Computing channel analysis...\")\n",
    "channel_data = analyzer.analyze_channels(\n",
    "    pre_time=PRE_TIME,\n",
    "    post_time=POST_TIME,\n",
    "    bin_size=BIN_SIZE\n",
    ")\n",
    "\n",
    "print(f\"Analysis computed for {len(channel_data)} channels\")\n",
    "\n",
    "# Display channel summary\n",
    "print(\"\\nChannel Summary:\")\n",
    "for channel, data in sorted(channel_data.items()):\n",
    "    print(f\"Channel {channel}: {data['n_units']} units, {data['total_spikes']} spikes, peak rate {np.max(data['firing_rate']):.1f} Hz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "208486f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot comprehensive channel analysis\n",
    "channel_fig = analyzer.plot_channel_analysis(channel_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281b584d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Channel correlation analysis\n",
    "print(\"Computing channel correlations...\")\n",
    "\n",
    "# Create correlation matrix between channels\n",
    "channels = sorted(channel_data.keys())\n",
    "firing_rates_matrix = np.array([channel_data[ch]['firing_rate'] for ch in channels])\n",
    "\n",
    "# Compute correlation matrix\n",
    "correlation_matrix = np.corrcoef(firing_rates_matrix)\n",
    "\n",
    "# Plot correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "im = plt.imshow(correlation_matrix, cmap='coolwarm', vmin=-1, vmax=1)\n",
    "plt.colorbar(im, label='Correlation')\n",
    "plt.xlabel('Channel')\n",
    "plt.ylabel('Channel')\n",
    "plt.title('Inter-Channel PSTH Correlation')\n",
    "\n",
    "# Add channel labels\n",
    "plt.xticks(range(len(channels)), channels)\n",
    "plt.yticks(range(len(channels)), channels)\n",
    "\n",
    "# Add correlation values to the plot\n",
    "for i in range(len(channels)):\n",
    "    for j in range(len(channels)):\n",
    "        plt.text(j, i, f'{correlation_matrix[i, j]:.2f}', \n",
    "                ha='center', va='center', \n",
    "                color='white' if abs(correlation_matrix[i, j]) > 0.5 else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Find most correlated channel pairs\n",
    "max_corr = 0\n",
    "max_pair = None\n",
    "for i, ch1 in enumerate(channels):\n",
    "    for j, ch2 in enumerate(channels):\n",
    "        if i < j and correlation_matrix[i, j] > max_corr:\n",
    "            max_corr = correlation_matrix[i, j]\n",
    "            max_pair = (ch1, ch2)\n",
    "\n",
    "if max_pair:\n",
    "    print(f\"\\nHighest channel correlation: {max_corr:.3f} between channels {max_pair[0]} and {max_pair[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5cfec11",
   "metadata": {},
   "source": [
    "## Statistical Analysis & Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd572fcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get comprehensive summary statistics\n",
    "summary_stats = analyzer.get_summary_statistics()\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"PSTH ANALYSIS SUMMARY\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "print(f\"\\nGeneral Statistics:\")\n",
    "print(f\"- Units analyzed: {summary_stats['n_units_analyzed']}\")\n",
    "print(f\"- Total intervals: {summary_stats['total_intervals']}\")\n",
    "print(f\"- Data time range: {summary_stats['data_time_range']['min']:.0f} - {summary_stats['data_time_range']['max']:.0f}\")\n",
    "\n",
    "print(f\"\\nAnalysis Parameters:\")\n",
    "print(f\"- Pre-stimulus time: {PRE_TIME} ms\")\n",
    "print(f\"- Post-stimulus time: {POST_TIME} ms\")\n",
    "print(f\"- Bin size: {BIN_SIZE} ms\")\n",
    "print(f\"- Smoothing: {SMOOTHING} bins\" if SMOOTHING else \"- No smoothing applied\")\n",
    "\n",
    "# Unit-specific statistics\n",
    "unit_stats = summary_stats['unit_statistics']\n",
    "baseline_rates = [stats['baseline_rate'] for stats in unit_stats.values()]\n",
    "peak_rates = [stats['peak_rate'] for stats in unit_stats.values()]\n",
    "modulation_ratios = [stats['modulation_ratio'] for stats in unit_stats.values() if stats['modulation_ratio'] != float('inf')]\n",
    "\n",
    "print(f\"\\nFiring Rate Statistics:\")\n",
    "print(f\"- Baseline rates: {np.mean(baseline_rates):.2f} Â± {np.std(baseline_rates):.2f} Hz\")\n",
    "print(f\"- Peak rates: {np.mean(peak_rates):.2f} Â± {np.std(peak_rates):.2f} Hz\")\n",
    "print(f\"- Modulation ratios: {np.mean(modulation_ratios):.2f} Â± {np.std(modulation_ratios):.2f}\")\n",
    "\n",
    "# Find most responsive units\n",
    "most_responsive = sorted(unit_stats.items(), key=lambda x: x[1]['modulation_ratio'], reverse=True)[:5]\n",
    "print(f\"\\nTop 5 Most Responsive Units:\")\n",
    "for unit, stats in most_responsive:\n",
    "    if stats['modulation_ratio'] != float('inf'):\n",
    "        print(f\"- Unit {unit}: {stats['modulation_ratio']:.2f}x modulation ({stats['baseline_rate']:.1f} â {stats['peak_rate']:.1f} Hz)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8587489",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze response characteristics\n",
    "print(\"\\nResponse Pattern Analysis:\")\n",
    "\n",
    "# Classify units by response type\n",
    "responsive_units = []\n",
    "suppressed_units = []\n",
    "non_responsive_units = []\n",
    "\n",
    "for unit, stats in unit_stats.items():\n",
    "    if stats['baseline_rate'] > 0:\n",
    "        modulation = stats['modulation_ratio']\n",
    "        if modulation > 1.5:  # 50% increase\n",
    "            responsive_units.append(unit)\n",
    "        elif modulation < 0.7:  # 30% decrease\n",
    "            suppressed_units.append(unit)\n",
    "        else:\n",
    "            non_responsive_units.append(unit)\n",
    "    else:\n",
    "        if stats['peak_rate'] > 0:\n",
    "            responsive_units.append(unit)\n",
    "        else:\n",
    "            non_responsive_units.append(unit)\n",
    "\n",
    "print(f\"- Responsive units (>50% increase): {len(responsive_units)} ({100*len(responsive_units)/len(unit_stats):.1f}%)\")\n",
    "print(f\"- Suppressed units (>30% decrease): {len(suppressed_units)} ({100*len(suppressed_units)/len(unit_stats):.1f}%)\")\n",
    "print(f\"- Non-responsive units: {len(non_responsive_units)} ({100*len(non_responsive_units)/len(unit_stats):.1f}%)\")\n",
    "\n",
    "# Plot response classification\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "# Response type pie chart\n",
    "labels = ['Responsive', 'Suppressed', 'Non-responsive']\n",
    "sizes = [len(responsive_units), len(suppressed_units), len(non_responsive_units)]\n",
    "colors = ['lightcoral', 'lightskyblue', 'lightgray']\n",
    "\n",
    "axes[0].pie(sizes, labels=labels, colors=colors, autopct='%1.1f%%', startangle=90)\n",
    "axes[0].set_title('Unit Response Classification')\n",
    "\n",
    "# Modulation ratio distribution\n",
    "valid_modulations = [stats['modulation_ratio'] for stats in unit_stats.values() \n",
    "                    if stats['modulation_ratio'] != float('inf') and stats['modulation_ratio'] < 10]\n",
    "\n",
    "axes[1].hist(valid_modulations, bins=20, alpha=0.7, edgecolor='black')\n",
    "axes[1].axvline(x=1, color='red', linestyle='--', label='No change')\n",
    "axes[1].axvline(x=1.5, color='green', linestyle='--', label='50% increase')\n",
    "axes[1].axvline(x=0.7, color='blue', linestyle='--', label='30% decrease')\n",
    "axes[1].set_xlabel('Modulation Ratio (Peak/Baseline)')\n",
    "axes[1].set_ylabel('Number of Units')\n",
    "axes[1].set_title('Distribution of Modulation Ratios')\n",
    "axes[1].legend()\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817d4c7a",
   "metadata": {},
   "source": [
    "## Custom Analysis Section\n",
    "\n",
    "Use this section for your own custom analyses. You can modify parameters and explore specific aspects of your data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b9301b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUSTOM ANALYSIS - Modify these parameters as needed\n",
    "\n",
    "# Example: Analyze with different time windows\n",
    "CUSTOM_PRE = 500   # Different pre-stimulus time\n",
    "CUSTOM_POST = 1500 # Different post-stimulus time\n",
    "CUSTOM_BIN = 25    # Smaller bin size for higher resolution\n",
    "\n",
    "print(f\"Running custom analysis with parameters:\")\n",
    "print(f\"- Pre-stimulus: {CUSTOM_PRE}ms\")\n",
    "print(f\"- Post-stimulus: {CUSTOM_POST}ms\") \n",
    "print(f\"- Bin size: {CUSTOM_BIN}ms\")\n",
    "\n",
    "# Compute PSTH with custom parameters\n",
    "custom_psth = analyzer.compute_psth(\n",
    "    pre_time=CUSTOM_PRE,\n",
    "    post_time=CUSTOM_POST,\n",
    "    bin_size=CUSTOM_BIN,\n",
    "    units=responsive_units[:5],  # Use only the most responsive units\n",
    "    smoothing_window=2\n",
    ")\n",
    "\n",
    "print(f\"Custom PSTH computed for {len(custom_psth)} responsive units\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be97215f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot custom analysis results\n",
    "if custom_psth:\n",
    "    # Update analyzer's psth_data temporarily for plotting\n",
    "    original_data = analyzer.psth_data.copy()\n",
    "    analyzer.psth_data = custom_psth\n",
    "    \n",
    "    # Create custom population plot\n",
    "    custom_fig = analyzer.plot_population_psth(method='mean')\n",
    "    plt.title(f'Custom PSTH - Responsive Units Only\\n({CUSTOM_PRE}ms pre, {CUSTOM_POST}ms post, {CUSTOM_BIN}ms bins)')\n",
    "    plt.show()\n",
    "    \n",
    "    # Restore original data\n",
    "    analyzer.psth_data = original_data\n",
    "else:\n",
    "    print(\"No data available for custom analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a43b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export analysis results\n",
    "print(\"Exporting analysis results...\")\n",
    "\n",
    "# Save summary statistics to CSV\n",
    "import json\n",
    "\n",
    "# Create a DataFrame with unit statistics\n",
    "unit_stats_df = pd.DataFrame(summary_stats['unit_statistics']).T\n",
    "unit_stats_df.to_csv('psth_unit_statistics.csv')\n",
    "print(\"Unit statistics saved to 'psth_unit_statistics.csv'\")\n",
    "\n",
    "# Save channel data\n",
    "channel_stats = []\n",
    "for channel, data in channel_data.items():\n",
    "    channel_stats.append({\n",
    "        'channel': channel,\n",
    "        'n_units': data['n_units'],\n",
    "        'total_spikes': data['total_spikes'],\n",
    "        'valid_intervals': data['valid_intervals'],\n",
    "        'peak_rate': np.max(data['firing_rate']),\n",
    "        'mean_rate': np.mean(data['firing_rate'])\n",
    "    })\n",
    "\n",
    "channel_stats_df = pd.DataFrame(channel_stats)\n",
    "channel_stats_df.to_csv('psth_channel_statistics.csv', index=False)\n",
    "print(\"Channel statistics saved to 'psth_channel_statistics.csv'\")\n",
    "\n",
    "print(\"\\nAnalysis complete! Check the generated CSV files for detailed statistics.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7964414",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook has provided a comprehensive analysis of your PSTH data including:\n",
    "\n",
    "1. **Data Overview**: Understanding the structure and distribution of your spike data\n",
    "2. **Individual Unit Analysis**: Detailed examination of specific units with raster plots and PSTHs\n",
    "3. **Population Analysis**: Overall patterns across multiple units\n",
    "4. **Channel Analysis**: Understanding activity patterns from a channel perspective\n",
    "5. **Statistical Summary**: Quantitative measures of responsiveness and modulation\n",
    "6. **Custom Analysis**: Flexible framework for your specific research questions\n",
    "\n",
    "### Key Features:\n",
    "- â Configurable time windows (pre/post stimulus)\n",
    "- â Unit selection and filtering\n",
    "- â Channel-based analysis\n",
    "- â Extensive visualizations (PSTHs, rasters, heatmaps, correlations)\n",
    "- â Statistical summaries and export capabilities\n",
    "- â Interactive parameter adjustment\n",
    "\n",
    "### Next Steps:\n",
    "- Modify the parameters in the configuration section to explore different time windows\n",
    "- Use the custom analysis section for specific research questions\n",
    "- Export results for further analysis in other tools\n",
    "- Extend the analysis with additional statistical tests as needed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
